{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task\n",
    "Load `data/dataset.csv` with Polars, inspect schema/shape/missingness/labels, explore text length & most common tokens, then train/evaluate a TFâ€‘IDF + linear classifier to predict whether a text is **human** or **AI**."
   ],
   "id": "67f9982d6dc4281f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:58:48.272010402Z",
     "start_time": "2025-12-12T14:58:46.220067001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='thomas-marquis', repo_name='ml-sandbox', mlflow=True)"
   ],
   "id": "3ab799adf3f553ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accessing as thomas-marquis\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as thomas-marquis\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"thomas-marquis/ml-sandbox\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"thomas-marquis/ml-sandbox\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Repository thomas-marquis/ml-sandbox initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository thomas-marquis/ml-sandbox initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:59:41.410959403Z",
     "start_time": "2025-12-12T14:59:36.832992991Z"
    }
   },
   "cell_type": "code",
   "source": "import mlflow",
   "id": "e1a8d26db277bee3",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:32.917296516Z",
     "start_time": "2025-12-12T14:45:32.711240899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "DATA_PATH = Path(\"data\") / \"dataset.csv\"\n",
    "assert DATA_PATH.exists(), f\"Missing dataset file: {DATA_PATH.resolve()}\"\n",
    "\n",
    "df = pl.read_csv(DATA_PATH, infer_schema_length=10_000)\n",
    "df.head()"
   ],
   "id": "1d44ed0e7366e817",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (5, 12)\n",
       "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ id  â”† label â”† topic     â”† text        â”† â€¦ â”† source_deta â”† timestamp   â”† plagiarism_ â”† notes      â”‚\n",
       "â”‚ --- â”† ---   â”† ---       â”† ---         â”†   â”† il          â”† ---         â”† score       â”† ---        â”‚\n",
       "â”‚ i64 â”† str   â”† str       â”† str         â”†   â”† ---         â”† str         â”† ---         â”† str        â”‚\n",
       "â”‚     â”†       â”†           â”†             â”†   â”† str         â”†             â”† f64         â”†            â”‚\n",
       "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 305 â”† human â”† food      â”† As someone  â”† â€¦ â”† author_50   â”† 2023-12-19  â”† 0.045       â”† personal_t â”‚\n",
       "â”‚     â”†       â”†           â”† who follows â”†   â”†             â”† 11:21:46    â”†             â”† one        â”‚\n",
       "â”‚     â”†       â”†           â”† food, Iâ€¦    â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â”‚ 341 â”† ai    â”† travel    â”† Analysis    â”† â€¦ â”† gpt-5-base  â”† 2024-04-01  â”† 0.007       â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† indicates   â”†   â”†             â”† 17:43:26    â”†             â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† that        â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† travelâ€¦     â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â”‚ 48  â”† human â”† education â”† I recently  â”† â€¦ â”† author_33   â”† 2025-08-28  â”† 0.163       â”† personal_t â”‚\n",
       "â”‚     â”†       â”†           â”† experienced â”†   â”†             â”† 07:56:09    â”†             â”† one        â”‚\n",
       "â”‚     â”†       â”†           â”† educatiâ€¦    â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â”‚ 68  â”† ai    â”† sports    â”† Analysis    â”† â€¦ â”† claude-2    â”† 2023-10-23  â”† 0.122       â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† indicates   â”†   â”†             â”† 14:34:48    â”†             â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† that        â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† sportsâ€¦     â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â”‚ 480 â”† human â”† finance   â”† In my       â”† â€¦ â”† author_87   â”† 2024-11-28  â”† 0.105       â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† experience, â”†   â”†             â”† 11:31:37    â”†             â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† finance     â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â”‚     â”†       â”†           â”† ofteâ€¦       â”†   â”†             â”†             â”†             â”†            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>label</th><th>topic</th><th>text</th><th>length_chars</th><th>length_words</th><th>quality_score</th><th>sentiment</th><th>source_detail</th><th>timestamp</th><th>plagiarism_score</th><th>notes</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>305</td><td>&quot;human&quot;</td><td>&quot;food&quot;</td><td>&quot;As someone who follows food, Iâ€¦</td><td>126</td><td>22</td><td>2.37</td><td>0.44</td><td>&quot;author_50&quot;</td><td>&quot;2023-12-19 11:21:46&quot;</td><td>0.045</td><td>&quot;personal_tone&quot;</td></tr><tr><td>341</td><td>&quot;ai&quot;</td><td>&quot;travel&quot;</td><td>&quot;Analysis indicates that travelâ€¦</td><td>141</td><td>19</td><td>3.44</td><td>0.6</td><td>&quot;gpt-5-base&quot;</td><td>&quot;2024-04-01 17:43:26&quot;</td><td>0.007</td><td>&quot;&quot;</td></tr><tr><td>48</td><td>&quot;human&quot;</td><td>&quot;education&quot;</td><td>&quot;I recently experienced educatiâ€¦</td><td>112</td><td>17</td><td>3.16</td><td>-0.43</td><td>&quot;author_33&quot;</td><td>&quot;2025-08-28 07:56:09&quot;</td><td>0.163</td><td>&quot;personal_tone&quot;</td></tr><tr><td>68</td><td>&quot;ai&quot;</td><td>&quot;sports&quot;</td><td>&quot;Analysis indicates that sportsâ€¦</td><td>101</td><td>14</td><td>3.32</td><td>0.44</td><td>&quot;claude-2&quot;</td><td>&quot;2023-10-23 14:34:48&quot;</td><td>0.122</td><td>&quot;&quot;</td></tr><tr><td>480</td><td>&quot;human&quot;</td><td>&quot;finance&quot;</td><td>&quot;In my experience, finance ofteâ€¦</td><td>78</td><td>14</td><td>3.52</td><td>-0.31</td><td>&quot;author_87&quot;</td><td>&quot;2024-11-28 11:31:37&quot;</td><td>0.105</td><td>&quot;&quot;</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:33.387782046Z",
     "start_time": "2025-12-12T14:45:33.019303543Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape, df.schema",
   "id": "e5736c9cd2937453",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 12),\n",
       " Schema([('id', Int64),\n",
       "         ('label', String),\n",
       "         ('topic', String),\n",
       "         ('text', String),\n",
       "         ('length_chars', Int64),\n",
       "         ('length_words', Int64),\n",
       "         ('quality_score', Float64),\n",
       "         ('sentiment', Float64),\n",
       "         ('source_detail', String),\n",
       "         ('timestamp', String),\n",
       "         ('plagiarism_score', Float64),\n",
       "         ('notes', String)]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:34.032925993Z",
     "start_time": "2025-12-12T14:45:33.547409299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Basic overview: nulls, uniques (approx), and small sample\n",
    "overview = pl.DataFrame(\n",
    "    {\n",
    "        \"column\": df.columns,\n",
    "        \"dtype\": [str(df.schema[c]) for c in df.columns],\n",
    "        \"null_count\": [df.select(pl.col(c).is_null().sum()).item() for c in df.columns],\n",
    "        \"n_unique\": [df.select(pl.col(c).n_unique()).item() for c in df.columns],\n",
    "    }\n",
    ").sort(\"null_count\", descending=True)\n",
    "\n",
    "overview"
   ],
   "id": "3092e5fb104c9be2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (12, 4)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ column           â”† dtype   â”† null_count â”† n_unique â”‚\n",
       "â”‚ ---              â”† ---     â”† ---        â”† ---      â”‚\n",
       "â”‚ str              â”† str     â”† i64        â”† i64      â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ id               â”† Int64   â”† 0          â”† 500      â”‚\n",
       "â”‚ label            â”† String  â”† 0          â”† 2        â”‚\n",
       "â”‚ topic            â”† String  â”† 0          â”† 10       â”‚\n",
       "â”‚ text             â”† String  â”† 0          â”† 459      â”‚\n",
       "â”‚ length_chars     â”† Int64   â”† 0          â”† 131      â”‚\n",
       "â”‚ â€¦                â”† â€¦       â”† â€¦          â”† â€¦        â”‚\n",
       "â”‚ sentiment        â”† Float64 â”† 0          â”† 143      â”‚\n",
       "â”‚ source_detail    â”† String  â”† 0          â”† 95       â”‚\n",
       "â”‚ timestamp        â”† String  â”† 0          â”† 500      â”‚\n",
       "â”‚ plagiarism_score â”† Float64 â”† 0          â”† 245      â”‚\n",
       "â”‚ notes            â”† String  â”† 0          â”† 2        â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column</th><th>dtype</th><th>null_count</th><th>n_unique</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;id&quot;</td><td>&quot;Int64&quot;</td><td>0</td><td>500</td></tr><tr><td>&quot;label&quot;</td><td>&quot;String&quot;</td><td>0</td><td>2</td></tr><tr><td>&quot;topic&quot;</td><td>&quot;String&quot;</td><td>0</td><td>10</td></tr><tr><td>&quot;text&quot;</td><td>&quot;String&quot;</td><td>0</td><td>459</td></tr><tr><td>&quot;length_chars&quot;</td><td>&quot;Int64&quot;</td><td>0</td><td>131</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;sentiment&quot;</td><td>&quot;Float64&quot;</td><td>0</td><td>143</td></tr><tr><td>&quot;source_detail&quot;</td><td>&quot;String&quot;</td><td>0</td><td>95</td></tr><tr><td>&quot;timestamp&quot;</td><td>&quot;String&quot;</td><td>0</td><td>500</td></tr><tr><td>&quot;plagiarism_score&quot;</td><td>&quot;Float64&quot;</td><td>0</td><td>245</td></tr><tr><td>&quot;notes&quot;</td><td>&quot;String&quot;</td><td>0</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:35.211657561Z",
     "start_time": "2025-12-12T14:45:34.805713817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Try to auto-detect likely text and label columns\n",
    "import re\n",
    "\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", s.lower())\n",
    "\n",
    "\n",
    "cols = df.columns\n",
    "norm = {_norm(c): c for c in cols}\n",
    "\n",
    "text_candidates = []\n",
    "for c in cols:\n",
    "    dt = df.schema[c]\n",
    "    if dt in (pl.Utf8, pl.String):\n",
    "        avg_len = df.select(pl.col(c).cast(pl.Utf8).str.len_chars().mean()).item()\n",
    "        text_candidates.append((c, float(avg_len) if avg_len is not None else -1.0))\n",
    "\n",
    "text_candidates_sorted = sorted(text_candidates, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "label_name_hints = {\"label\", \"target\", \"class\", \"y\", \"source\", \"author\", \"isai\", \"ai\", \"human\"}\n",
    "label_candidates = [c for c in cols if _norm(c) in label_name_hints or any(h in _norm(c) for h in label_name_hints)]\n",
    "\n",
    "text_col = text_candidates_sorted[0][0] if text_candidates_sorted else None\n",
    "label_col = label_candidates[0] if label_candidates else None\n",
    "\n",
    "text_candidates_sorted[:10], label_candidates, (text_col, label_col)"
   ],
   "id": "86d1621f55b138e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('text', 115.152),\n",
       "  ('timestamp', 19.0),\n",
       "  ('source_detail', 9.468),\n",
       "  ('topic', 7.636),\n",
       "  ('notes', 4.082),\n",
       "  ('label', 3.494)],\n",
       " ['label', 'quality_score', 'source_detail'],\n",
       " ('text', 'label'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:37.025315893Z",
     "start_time": "2025-12-12T14:45:35.393529760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show value counts for label candidates (helps pick the right label column)\n",
    "for c in label_candidates[:5]:\n",
    "    print(f\"\\n=== {c} ===\")\n",
    "    display(\n",
    "        df.select(pl.col(c)).with_columns(pl.col(c).cast(pl.Utf8)).group_by(c).len().sort(\"len\", descending=True).head(\n",
    "            20))"
   ],
   "id": "b5c311aad81e7407",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== label ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shape: (2, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
       "â”‚ label â”† len â”‚\n",
       "â”‚ ---   â”† --- â”‚\n",
       "â”‚ str   â”† u32 â”‚\n",
       "â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
       "â”‚ ai    â”† 251 â”‚\n",
       "â”‚ human â”† 249 â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>label</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;ai&quot;</td><td>251</td></tr><tr><td>&quot;human&quot;</td><td>249</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== quality_score ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shape: (20, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
       "â”‚ quality_score â”† len â”‚\n",
       "â”‚ ---           â”† --- â”‚\n",
       "â”‚ str           â”† u32 â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
       "â”‚ 2.77          â”† 5   â”‚\n",
       "â”‚ 3.2           â”† 5   â”‚\n",
       "â”‚ 3.85          â”† 5   â”‚\n",
       "â”‚ 4.4           â”† 5   â”‚\n",
       "â”‚ 4.04          â”† 5   â”‚\n",
       "â”‚ â€¦             â”† â€¦   â”‚\n",
       "â”‚ 3.18          â”† 4   â”‚\n",
       "â”‚ 3.54          â”† 4   â”‚\n",
       "â”‚ 2.88          â”† 4   â”‚\n",
       "â”‚ 3.16          â”† 4   â”‚\n",
       "â”‚ 3.82          â”† 4   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>quality_score</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;2.77&quot;</td><td>5</td></tr><tr><td>&quot;3.2&quot;</td><td>5</td></tr><tr><td>&quot;3.85&quot;</td><td>5</td></tr><tr><td>&quot;4.4&quot;</td><td>5</td></tr><tr><td>&quot;4.04&quot;</td><td>5</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;3.18&quot;</td><td>4</td></tr><tr><td>&quot;3.54&quot;</td><td>4</td></tr><tr><td>&quot;2.88&quot;</td><td>4</td></tr><tr><td>&quot;3.16&quot;</td><td>4</td></tr><tr><td>&quot;3.82&quot;</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== source_detail ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shape: (20, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
       "â”‚ source_detail â”† len â”‚\n",
       "â”‚ ---           â”† --- â”‚\n",
       "â”‚ str           â”† u32 â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
       "â”‚ claude-2      â”† 61  â”‚\n",
       "â”‚ bloomz-7b     â”† 51  â”‚\n",
       "â”‚ gpt-5-base    â”† 50  â”‚\n",
       "â”‚ gpt-4o-mini   â”† 46  â”‚\n",
       "â”‚ llama-3-small â”† 43  â”‚\n",
       "â”‚ â€¦             â”† â€¦   â”‚\n",
       "â”‚ author_87     â”† 4   â”‚\n",
       "â”‚ author_32     â”† 4   â”‚\n",
       "â”‚ author_93     â”† 4   â”‚\n",
       "â”‚ author_59     â”† 4   â”‚\n",
       "â”‚ author_20     â”† 4   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_detail</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;claude-2&quot;</td><td>61</td></tr><tr><td>&quot;bloomz-7b&quot;</td><td>51</td></tr><tr><td>&quot;gpt-5-base&quot;</td><td>50</td></tr><tr><td>&quot;gpt-4o-mini&quot;</td><td>46</td></tr><tr><td>&quot;llama-3-small&quot;</td><td>43</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;author_87&quot;</td><td>4</td></tr><tr><td>&quot;author_32&quot;</td><td>4</td></tr><tr><td>&quot;author_93&quot;</td><td>4</td></tr><tr><td>&quot;author_59&quot;</td><td>4</td></tr><tr><td>&quot;author_20&quot;</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:38.291893673Z",
     "start_time": "2025-12-12T14:45:37.607001948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If label_col wasn't found well, fall back to any low-cardinality column as label\n",
    "if label_col is None:\n",
    "    low_card = []\n",
    "    for c in df.columns:\n",
    "        if df.schema[c] in (pl.Utf8, pl.String, pl.Int64, pl.Int32, pl.Int16, pl.Int8, pl.UInt64, pl.UInt32, pl.UInt16,\n",
    "                            pl.UInt8, pl.Boolean):\n",
    "            nu = df.select(pl.col(c).n_unique()).item()\n",
    "            if nu is not None and 1 < nu <= 20:\n",
    "                low_card.append((c, int(nu)))\n",
    "    low_card = sorted(low_card, key=lambda x: x[1])\n",
    "    low_card[:15]"
   ],
   "id": "bf046c6084f4b3ac",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:38.919334527Z",
     "start_time": "2025-12-12T14:45:38.362986303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Text stats: length distribution and empties for the chosen text_col\n",
    "assert text_col is not None, \"Could not infer a text column.\"\n",
    "text_stats = (\n",
    "    df.select(\n",
    "        pl.col(text_col).cast(pl.Utf8).alias(\"text\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").fill_null(\"\").alias(\"text\"),\n",
    "        pl.col(\"text\").str.len_chars().alias(\"n_chars\"),\n",
    "        pl.col(\"text\").str.count_matches(r\"\\S+\").alias(\"n_tokens_approx\"),\n",
    "        (pl.col(\"text\").str.strip_chars().str.len_chars() == 0).alias(\"is_empty\"),\n",
    "    )\n",
    "    .select(\n",
    "        pl.len().alias(\"n_rows\"),\n",
    "        pl.col(\"is_empty\").sum().alias(\"n_empty\"),\n",
    "        pl.col(\"n_chars\").mean().alias(\"mean_chars\"),\n",
    "        pl.col(\"n_chars\").median().alias(\"median_chars\"),\n",
    "        pl.col(\"n_chars\").quantile(0.95).alias(\"p95_chars\"),\n",
    "        pl.col(\"n_tokens_approx\").mean().alias(\"mean_tokens_approx\"),\n",
    "        pl.col(\"n_tokens_approx\").median().alias(\"median_tokens_approx\"),\n",
    "        pl.col(\"n_tokens_approx\").quantile(0.95).alias(\"p95_tokens_approx\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "text_stats"
   ],
   "id": "3ef5bbf006ccf01e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (1, 8)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚ n_rows â”† n_empty â”† mean_chars â”† median_char â”† p95_chars â”† mean_tokens â”† median_toke â”† p95_tokens â”‚\n",
       "â”‚ ---    â”† ---     â”† ---        â”† s           â”† ---       â”† _approx     â”† ns_approx   â”† _approx    â”‚\n",
       "â”‚ u32    â”† u32     â”† f64        â”† ---         â”† f64       â”† ---         â”† ---         â”† ---        â”‚\n",
       "â”‚        â”†         â”†            â”† f64         â”†           â”† f64         â”† f64         â”† f64        â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 500    â”† 0       â”† 115.152    â”† 103.0       â”† 205.0     â”† 16.798      â”† 14.0        â”† 30.0       â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>n_rows</th><th>n_empty</th><th>mean_chars</th><th>median_chars</th><th>p95_chars</th><th>mean_tokens_approx</th><th>median_tokens_approx</th><th>p95_tokens_approx</th></tr><tr><td>u32</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>500</td><td>0</td><td>115.152</td><td>103.0</td><td>205.0</td><td>16.798</td><td>14.0</td><td>30.0</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:39.650016949Z",
     "start_time": "2025-12-12T14:45:39.210768412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Quick token frequency (lowercased, alnum words length>=3), sample-based for speed on big data\n",
    "sample_n = min(df.height, 50_000)\n",
    "\n",
    "tokens = (\n",
    "    df.select(pl.col(text_col).cast(pl.Utf8).fill_null(\"\").alias(\"text\"))\n",
    "    .head(sample_n)\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").str.to_lowercase().str.extract_all(r\"[a-z0-9]{3,}\").alias(\"tokens\")\n",
    "    )\n",
    "    .select(pl.col(\"tokens\").explode().alias(\"token\"))\n",
    "    .filter(pl.col(\"token\").is_not_null() & (pl.col(\"token\").str.len_chars() > 0))\n",
    "    .group_by(\"token\")\n",
    "    .len()\n",
    "    .sort(\"len\", descending=True)\n",
    "    .head(30)\n",
    ")\n",
    "\n",
    "tokens"
   ],
   "id": "dd5e746c0b486f1d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (30, 2)\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
       "â”‚ token      â”† len â”‚\n",
       "â”‚ ---        â”† --- â”‚\n",
       "â”‚ str        â”† u32 â”‚\n",
       "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡\n",
       "â”‚ that       â”† 219 â”‚\n",
       "â”‚ the        â”† 194 â”‚\n",
       "â”‚ with       â”† 171 â”‚\n",
       "â”‚ can        â”† 136 â”‚\n",
       "â”‚ this       â”† 132 â”‚\n",
       "â”‚ â€¦          â”† â€¦   â”‚\n",
       "â”‚ heuristics â”† 67  â”‚\n",
       "â”‚ optimized  â”† 67  â”‚\n",
       "â”‚ simple     â”† 67  â”‚\n",
       "â”‚ offs       â”† 65  â”‚\n",
       "â”‚ there      â”† 65  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (30, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>token</th><th>len</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;that&quot;</td><td>219</td></tr><tr><td>&quot;the&quot;</td><td>194</td></tr><tr><td>&quot;with&quot;</td><td>171</td></tr><tr><td>&quot;can&quot;</td><td>136</td></tr><tr><td>&quot;this&quot;</td><td>132</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;heuristics&quot;</td><td>67</td></tr><tr><td>&quot;optimized&quot;</td><td>67</td></tr><tr><td>&quot;simple&quot;</td><td>67</td></tr><tr><td>&quot;offs&quot;</td><td>65</td></tr><tr><td>&quot;there&quot;</td><td>65</td></tr></tbody></table></div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:44.667777996Z",
     "start_time": "2025-12-12T14:45:40.021685801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build TF-IDF classifier (scikit-learn): auto-normalize labels to {human, ai}\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "assert label_col is not None, \"Could not infer a label column (set label_col manually in a new cell if needed).\"\n",
    "\n",
    "data_ml = (\n",
    "    df.select(\n",
    "        pl.col(text_col).cast(pl.Utf8).alias(\"text\"),\n",
    "        pl.col(label_col).alias(\"label_raw\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"text\").fill_null(\"\").alias(\"text\"),\n",
    "        pl.col(\"label_raw\").cast(pl.Utf8).str.to_lowercase().fill_null(\"\").alias(\"label_raw\"),\n",
    "    )\n",
    "    .filter(pl.col(\"text\").str.strip_chars().str.len_chars() > 0)\n",
    ")\n",
    "\n",
    "\n",
    "def normalize_label(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    if s in {\"ai\", \"machine\", \"gpt\", \"llm\", \"assistant\", \"generated\", \"synthetic\", \"bot\", \"chatgpt\"}:\n",
    "        return \"ai\"\n",
    "    if s in {\"human\", \"person\", \"written\", \"organic\", \"real\"}:\n",
    "        return \"human\"\n",
    "    # numeric-ish / boolean-ish common cases\n",
    "    if s in {\"1\", \"true\", \"yes\"}:\n",
    "        return \"ai\"\n",
    "    if s in {\"0\", \"false\", \"no\"}:\n",
    "        return \"human\"\n",
    "    # heuristic substring\n",
    "    if \"ai\" in s or \"gpt\" in s or \"llm\" in s or \"machine\" in s or \"synthetic\" in s:\n",
    "        return \"ai\"\n",
    "    if \"human\" in s:\n",
    "        return \"human\"\n",
    "    return s\n",
    "\n",
    "\n",
    "labels = data_ml.select(pl.col(\"label_raw\")).to_series().to_list()\n",
    "labels_norm = [normalize_label(x) for x in labels]\n",
    "\n",
    "X = data_ml.select(pl.col(\"text\")).to_series().to_list()\n",
    "y = np.array(labels_norm, dtype=object)\n",
    "\n",
    "# Keep only binary {human, ai}\n",
    "mask = np.isin(y, [\"human\", \"ai\"])\n",
    "X = [t for t, m in zip(X, mask) if m]\n",
    "y = y[mask]\n",
    "\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "unique, counts"
   ],
   "id": "10036275605023b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ai', 'human'], dtype=object), array([251, 249]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T15:03:17.047276270Z",
     "start_time": "2025-12-12T15:02:50.668939089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train/evaluate\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            strip_accents=\"unicode\",\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True,\n",
    "        )),\n",
    "        (\"lr\", LogisticRegression(\n",
    "            max_iter=2000,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=None,\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Confusion matrix [human, ai] rows x cols:\")\n",
    "print(confusion_matrix(y_test, y_pred, labels=[\"human\", \"ai\"]))\n",
    "\n",
    "if hasattr(clf[-1], \"predict_proba\"):\n",
    "    proba = clf.predict_proba(X_test)\n",
    "    ai_idx = list(clf.classes_).index(\"ai\")\n",
    "    auc = roc_auc_score((y_test == \"ai\").astype(int), proba[:, ai_idx])\n",
    "    print(f\"ROC-AUC (ai vs human): {auc:.4f}\")\n",
    "\n",
    "mlflow.sklearn.log_model(\n",
    "    sk_model=clf,\n",
    "    name=\"ai-human-clfr\",\n",
    "    input_example=X_train,\n",
    "    registered_model_name=\"ai-human-clfr\",\n",
    ")"
   ],
   "id": "faa1bf31175eba37",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 16:02:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/12/12 16:02:51 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b2e0b69c8af646e5a19dd033b6e636cf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/12/12 16:02:51 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "2025/12/12 16:02:55 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/12/12 16:02:58 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run luminous-rat-552 at: https://dagshub.com/thomas-marquis/ml-sandbox.mlflow/#/experiments/0/runs/b2e0b69c8af646e5a19dd033b6e636cf\n",
      "ğŸ§ª View experiment at: https://dagshub.com/thomas-marquis/ml-sandbox.mlflow/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 16:03:02 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "2025/12/12 16:03:02 WARNING mlflow.sklearn: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ai     1.0000    1.0000    1.0000        50\n",
      "       human     1.0000    1.0000    1.0000        50\n",
      "\n",
      "    accuracy                         1.0000       100\n",
      "   macro avg     1.0000    1.0000    1.0000       100\n",
      "weighted avg     1.0000    1.0000    1.0000       100\n",
      "\n",
      "Confusion matrix [human, ai] rows x cols:\n",
      "[[50  0]\n",
      " [ 0 50]]\n",
      "ROC-AUC (ai vs human): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 16:03:02 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: AttributeError(\"'int' object has no attribute 'lower'\"). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`.\n",
      "2025/12/12 16:03:05 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Successfully registered model 'ai-human-clfr'.\n",
      "2025/12/12 16:03:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ai-human-clfr, version 1\n",
      "Created version '1' of model 'ai-human-clfr'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7c5853018190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T14:45:44.933141207Z",
     "start_time": "2025-12-12T14:45:44.876266553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspect most indicative features for each class (top weighted ngrams)\n",
    "import numpy as np\n",
    "\n",
    "tfidf = clf.named_steps[\"tfidf\"]\n",
    "lr = clf.named_steps[\"lr\"]\n",
    "\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "coef = lr.coef_[0]\n",
    "classes = list(lr.classes_)\n",
    "ai_positive = \"ai\" if classes[1] == \"ai\" else classes[0]\n",
    "\n",
    "# coef corresponds to classes_[1] vs classes_[0] in binary for LogisticRegression\n",
    "# We'll derive directions based on which class is treated as positive in coef sign:\n",
    "positive_class = classes[1]\n",
    "neg_class = classes[0]\n",
    "\n",
    "top_k = 25\n",
    "top_pos_idx = np.argsort(coef)[-top_k:][::-1]\n",
    "top_neg_idx = np.argsort(coef)[:top_k]\n",
    "\n",
    "print(f\"Positive direction => {positive_class}\")\n",
    "print(\"Top features:\")\n",
    "for i in top_pos_idx:\n",
    "    print(f\"{feature_names[i]:<30} {coef[i]: .4f}\")\n",
    "\n",
    "print(f\"\\nNegative direction => {neg_class}\")\n",
    "print(\"Top features:\")\n",
    "for i in top_neg_idx:\n",
    "    print(f\"{feature_names[i]:<30} {coef[i]: .4f}\")\n"
   ],
   "id": "4243b88bc6628d31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive direction => human\n",
      "Top features:\n",
      "my                              1.9848\n",
      "to                              1.3932\n",
      "personal opinion                1.3251\n",
      "personal                        1.3251\n",
      "my personal                     1.3251\n",
      "is that                         1.3251\n",
      "opinion                         1.3251\n",
      "opinion on                      1.3251\n",
      "in                              1.2832\n",
      "in my                           1.2832\n",
      "who                             1.1839\n",
      "who follows                     1.1839\n",
      "as someone                      1.1839\n",
      "someone                         1.1839\n",
      "someone who                     1.1839\n",
      "follows                         1.1839\n",
      "believe                         1.1839\n",
      "day                             1.0928\n",
      "as                              1.0848\n",
      "my experience                   0.9591\n",
      "experience                      0.9591\n",
      "often leads                     0.9591\n",
      "often                           0.9591\n",
      "leads to                        0.9591\n",
      "leads                           0.9591\n",
      "\n",
      "Negative direction => ai\n",
      "Top features:\n",
      "summary                        -1.6153\n",
      "summary on                     -1.6153\n",
      "this article                   -1.2028\n",
      "discusses                      -1.2028\n",
      "article discusses              -1.2028\n",
      "highlights that                -1.2028\n",
      "article                        -1.2028\n",
      "and highlights                 -1.2028\n",
      "highlights                     -1.2028\n",
      "concise overview               -1.1752\n",
      "overview                       -1.1752\n",
      "overview of                    -1.1752\n",
      "concise                        -1.1752\n",
      "shows                          -1.1030\n",
      "following summary              -1.1030\n",
      "the following                  -1.1030\n",
      "following                      -1.1030\n",
      "is associated                  -1.0617\n",
      "associated                     -1.0617\n",
      "associated with                -1.0617\n",
      "indicates that                 -1.0617\n",
      "analysis                       -1.0617\n",
      "analysis indicates             -1.0617\n",
      "indicates                      -1.0617\n",
      "research                       -0.9209\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
